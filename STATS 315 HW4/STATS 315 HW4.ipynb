{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 4: From Data To Model**"
      ],
      "metadata": {
        "id": "3q0t9NSN5Qr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this homework we will focus on going from the data to a model that generalizes well."
      ],
      "metadata": {
        "id": "Np9y8zs45YZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "BHT6b3t-5x3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "2gr07UbKekuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Warmup\n",
        "We will first start off again with the california housing dataset"
      ],
      "metadata": {
        "id": "YwhtwsF9Zm1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9i_4yxz-Pnf"
      },
      "outputs": [],
      "source": [
        "california_housing = fetch_california_housing(return_X_y=True, as_frame=True)\n",
        "X = california_housing[0]\n",
        "y = california_housing[1]\n",
        "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train_unscaled)\n",
        "X_test = sc.transform(X_test_unscaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 1 (9 pts):\n",
        "Recreate the regression model created in HW3 using tf.keras.Sequential. While you will have to use the same amount of epochs and batch size, for the optimizer you can use RMSprop with the same learning rate as in HW3.</b></h6></font>\n",
        "\n"
      ],
      "metadata": {
        "id": "Te154e8fcqbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q1():\n",
        "  \"\"\"A function that returns a compiled model that matches the regression\n",
        "  problem in HW3\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass\n",
        "\n",
        "model_q1 = q1()\n",
        "model_q1.fit(X_train,y_train, epochs=100, batch_size=1000)"
      ],
      "metadata": {
        "id": "0TafZmqjeiqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: MNIST to Model\n",
        "Now we shall switch to the MNIST dataset"
      ],
      "metadata": {
        "id": "zrKeX5cMjnFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y_int), _ = mnist.load_data()\n",
        "X = X.reshape(X.shape[0],-1)\n",
        "y_one_hot = to_categorical(y_int, num_classes=10)\n",
        "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.3, random_state=42)\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train_unscaled)\n",
        "X_test = sc.transform(X_test_unscaled)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nayLXMgwjsff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 2 (9 pts): \n",
        "Create a model that underfits the data after at least 50 epochs. (For the loss use cross entropy)</b></h6></font>"
      ],
      "metadata": {
        "id": "bHALbapZXup0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q2():\n",
        "  \"\"\"A function that returns a compiled model that underfits the data\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "j2PDoysikLSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q2 = q2()\n",
        "history_q2 = model_q2.fit(X_train,y_train, epochs=50, batch_size=2048, validation_data=(X_valid, y_valid))\n"
      ],
      "metadata": {
        "id": "YFLdK5pkkxte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = history_q2.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss)+1),val_loss)"
      ],
      "metadata": {
        "id": "AgjsZRCkoESq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b> Question 3 (9 pts): \n",
        "Take the model from question 2 and change it/tweak hyperparameters until it is able to overfit the data. (The resulting model does not need to be similar to the answer in question 2.)</b></h6></font>"
      ],
      "metadata": {
        "id": "et4BRJC0Yt1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q3():\n",
        "  \"\"\"A function that returns a compiled model that overfits the data\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "s41cPaXRY3lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ep = 20\n",
        "bs = 512"
      ],
      "metadata": {
        "id": "ghE7Opf6rAaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q3 = q3()\n",
        "history_q3 = model_q3.fit(X_train,y_train, epochs=ep, batch_size=bs, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "QzLQ3vZMZKXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation loss\n",
        "val_loss = history_q3.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss)+1),val_loss)"
      ],
      "metadata": {
        "id": "zR-rBGwbZP68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 4 (9 pts): \n",
        "From your model in question 3, what do you think is the best stopping point? Note your answer below and why you think it. Then, Use keras early stopping on your model from question 3 to have keras automatically do it for you. Hint: use the tensorflow docs to learn how to use the earlystopping callback</b></h6></font>"
      ],
      "metadata": {
        "id": "bXTZDO1Ygjvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write what you think here**"
      ],
      "metadata": {
        "id": "yGq4cNOojplb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code goes here"
      ],
      "metadata": {
        "id": "MEy0sTsoigOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation loss\n",
        "val_loss = history_q4.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss)+1),val_loss)"
      ],
      "metadata": {
        "id": "sCCtyrXYjFPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 5 (9 pts): \n",
        "Starting with your model from question 3, try to regularize it by reducing size of network. State the process you went through on how you settled on your model.</b></h6></font>"
      ],
      "metadata": {
        "id": "iuWfF37VkXEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write here**"
      ],
      "metadata": {
        "id": "hcLnLwS-CFFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q5():\n",
        "  \"\"\"A function that returns a compiled model that has been reduced in size\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "-M_LYJvrUlUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q5 = q5()\n",
        "history_q5 = model_q5.fit(X_train,y_train, epochs=ep, batch_size=bs, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "kDztjuXWU9VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the loss compared to original model\n",
        "val_loss_q5 = history_q5.history[\"val_loss\"]\n",
        "val_loss_q3 = history_q3.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q3)+1),val_loss_q3, label=\"original\")\n",
        "plt.plot(np.arange(1,len(val_loss_q5)+1),val_loss_q5, label=\"reduced size\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Z3iS4nrOoeiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 6 (9 pts):\n",
        "Starting with your model from question 3, try to regularize it by using by L1 regularization. State the process you went through on how you settled on your model.</b></h6></font>"
      ],
      "metadata": {
        "id": "3KSoAc4Rjw6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write here**"
      ],
      "metadata": {
        "id": "mk4MDVbpCLz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q6():\n",
        "  \"\"\"A function that returns a compiled model that has been regularized using L1\n",
        "  regularization.\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "WjHkc3Y3UnoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q6 = q6()\n",
        "history_q6 = model_q6.fit(X_train,y_train, epochs=ep, batch_size=bs, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "Dq60VFwUXELu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_q3 = history_q3.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q3)+1),val_loss_q3, label=\"original\")\n",
        "val_loss_q6 = history_q6.history[\"val_categorical_crossentropy\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q6)+1),val_loss_q6, label=\"L1 reg\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "bJP6pj04qHct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 7 (9 pts): \n",
        "Starting with your model from question 3, try to regularize it by using L2 regularization. State the process you went through on how you settled on your model.</b></h6></font>"
      ],
      "metadata": {
        "id": "8BI7o8VJkW3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write here**"
      ],
      "metadata": {
        "id": "lNfZ78dZCP06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q7():\n",
        "  \"\"\"A function that returns a compiled model that has been regularized using L2\n",
        "  regularization.\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "3V3r4iZ4Up2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q7 = q7()\n",
        "history_q7 = model_q7.fit(X_train,y_train, epochs=ep, batch_size=bs, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "VukA4rRLsgpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_q3 = history_q3.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q3)+1),val_loss_q3, label=\"original\")\n",
        "val_loss_q7 = history_q7.history[\"val_categorical_crossentropy\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q7)+1),val_loss_q7, label=\"L2 reg\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "0AAEPyzhs79Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 8 (9 pts):\n",
        "Starting with your model from question 3, try to regularize it by using dropout. State the process you went through on how you settled on your model.</b></h6></font>"
      ],
      "metadata": {
        "id": "cKw_lYqVkvtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write here**"
      ],
      "metadata": {
        "id": "VQ3VVM-UCU7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q8():\n",
        "  \"\"\"A function that returns a compiled model that has been regularized using\n",
        "  dropout.\n",
        "  Args: None\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "Jy4NB47cUrst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q8 = q8()\n",
        "history_q8 = model_q8.fit(X_train,y_train, epochs=ep, batch_size=bs, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "L-LYjWGgtSmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_q3 = history_q3.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q3)+1),val_loss_q3, label=\"original\")\n",
        "val_loss_q8 = history_q8.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q8)+1),val_loss_q8, label=\"dropout\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ZfzaAcgVtTC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 9 (9 pts):\n",
        "Starting with your model from question 3, try to regularize it by using a combination of the methods used in questions 5-8. Make changes to hyperparameters and have the model stop at a good epoch. State the process you went through on how you settled on your model.</b></h6></font>"
      ],
      "metadata": {
        "id": "8-DggF-Tmfij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write here**"
      ],
      "metadata": {
        "id": "rIsXRto3CaZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q9():\n",
        "  \"\"\"A function that returns a compiled model that has been regularized using\n",
        "  various methods.\n",
        "  Returns: A tf.keras.Sequential model that has been compiled\"\"\"\n",
        "  #your code here\n",
        "  pass"
      ],
      "metadata": {
        "id": "V6N25o2lUtvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_q9 = q9()\n",
        "history_q9 = model_q9.fit(X_train,y_train, epochs=50, batch_size=256, validation_data=(X_valid, y_valid), callbacks=[es])"
      ],
      "metadata": {
        "id": "jlyndLU6uJMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_q3 = history_q3.history[\"val_loss\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q3)+1),val_loss_q3, label=\"original\")\n",
        "val_loss_q9 = history_q9.history[\"val_categorical_crossentropy\"]\n",
        "plt.plot(np.arange(1,len(val_loss_q9)+1),val_loss_q9, label=\"dropout/L2 reg/reduced size/early stop\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-zX4c9aluQHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 10 (9 pts):\n",
        "Take the models from question 2 to 9 and find their test loss.</b></h6></font>"
      ],
      "metadata": {
        "id": "Amet5y_ik1a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model_q2, model_q3, model_q4, model_q5, model_q6, model_q7, model_q8, \n",
        "          model_q9]   #the models to find test loss of\n",
        "#your code here"
      ],
      "metadata": {
        "id": "Uc8pWmPqUvXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h6><b>Question 11 (10 pts): If you had to use one of these models, which one would you use and why?</b></h6></font>"
      ],
      "metadata": {
        "id": "hsIdJxMrlIW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your answer here**"
      ],
      "metadata": {
        "id": "C2JsFxw9Uv-5"
      }
    }
  ]
}